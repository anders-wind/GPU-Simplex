% !TeX spellcheck=en_GB
\section{Implementation}

This section contains a description of our implementation of parallel Multi-Simplex in Futhark as well as our benchmarking strategy.

\subsection{Futhark Implementations}
We have implemented the three parallel versions of Multi-Simplex in the functional programming language Futhark, which generates code optimised for parallel execution on the GPU. The implementations roughly follow the pseudocode in Figure \ref{code:multi-simplex}, with the exception of the fully parallel version, which has been completely flattened.

For all implementations, the solutions are represented in single-precision 32-bit floats, mostly for efficiency purposes. We have not experienced any problems with the precision of our results, although it should be noted that Simplex in general can be prone to numerical instability. From inspecting our results, they are sometimes off by a tiny amount, which is accounted for by Futhark in its test suite when comparing floats.

The implementations can be seen in files \texttt{simplex-outer-parallel.fut}, \texttt{simplex-inner-parallel.fut}, and \texttt{simplex-full-parallel.fut}.

To run the code, \todo{... instructions} This requires that you run on a machine with a GPU and that Futhark and Python are installed.

\subsection{Test Instance Generation}
In order to test our implementation and generate data sets for benchmarking, we have implemented a Simplex instance generator in java. To compute the expected results, we use an off-the-shelf linear programming library, which is also the one we use for baseline comparison in the benchmarks.

\newpar A Simplex test instance consists of the constraints matrix $A$, the constants vector $b$, and the coefficients vector $c$.
We (somewhat arbitrarily) choose coefficients and constraints to be random integers between 0 and 100. We make sure that all columns in the constraints matrix contain at least one non-zero coefficient. If there was a variable with all-zero coefficients in $A$, it would be completely unconstrained and the problem would be unbounded. The constants are the upper bounds for the constraints, therefore we choose them to be random integers between 100 and 500 to make sure the instances do not converge too quickly.

\newpar The instance generator can be used to generate multiple instances of different sizes to allow testing how differing dimension lengths and number of instances can influence the running time of the different implementations. Since Futhark does not allow irregular arrays, the test data for the versions that are not completely flattened must be padded with zeroes.

To ensure a fair comparison between the implementations, the flattening of the input is precomputed. This resembles the real world use case where data could simply be generated in the correct format.

\subsection{Benchmarking}
To compare to our solution with an off-the-shelf algorithm, the CPLEX framework was chosen, which is developed and maintained by IBM\footnote{\url{http://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/index.html}}. It is one of the most used optimization frameworks and can solve both linear and integer linear programs efficiently.

The Futhark benchmarks are measured using the inbuilt \texttt{futhark-bench} functionality which also tests that the output data has the expected values. It runs each test 10 times and measures the execution of the program not including the initial and final copying of data to and from the GPU. The CPLEX benchmarks are measured with our own implementation which uses a wall clock timer to measure the time it takes for CPLEX to solve the instances, not including the setup and initialisation. This is repeated 6 times, as any more was too strenuous on our systems with the size of the data generated.

We tested the GPU implementations on a CentOS 7 Server with an Intel E5-4660 V4 processor, 126 GB memory and with Nvidia GTX 780ti. Both the CPLEX framework and the sequentiel 
implementation were tested on a Ubuntu 14.04 machine with 8 GB memory and an Intel i5-4200U, due to the fact that we did not have permission to install CPLEX on the server.

\newpar Our benchmarks comprise four categories of tests which represent instances where different dimensions are the dominant or limited. By doing so, different weaknesses in the implementations can be revealed.

First category is one instance where the dimensions of the linear program is large. Second category is many small instances to showcase how well the algorithm handles parallelism across instances. Third category contains many instances of big size to allow for huge parallelism and the fourth category contains many instances of varying size to simulate potential real data which might not always be uniform.